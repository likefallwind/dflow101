# dflow101
With the advent of the AI4S era, concurrent learning, high-throughput computing, and distributed and heterogeneous infrastructure poke the pain points of the traditional workflow solutions. **dflow** aims to provide all scientists and engineers with scientific computing workflow. **dflow** is a cloud-native scientific computing workflow framework based on the Argo workflow engine that can be geared towards the needs and usage habits of the scientific computing community, combining the characteristics of AI, computing resources, and scientific computing.

Here, **dflow101** project hopes to encourage increasingly more scientific work using this kind of advanced workflow. 

## dflow documents
In [dflow repo](https://github.com/deepmodeling/dflow), there are several documents for your reference to help you get started quickly.
- [Overview](https://github.com/deepmodeling/dflow#1--overview)
- [Installation and Set-up](https://github.com/deepmodeling/dflow/tree/master/scripts)
- [User guide (dflow-docs)](https://github.com/deepmodeling/dflow#UserGuide)
- [Get-started tutorials](https://github.com/deepmodeling/dflow/tree/master/tutorials)

## dflow projects
- 

## Join us
We welcome anyone interested to join **dflow101**. The expected dflow project can be released in your own Github repo, including a README document, executable python scripts and supporting files (e.g. uploaded files, Dockerfile and others). 

For more information, please refer to  [submission_guidelines.md](https://github.com/veritas496/dflow101/blob/main/submission_guidelines.md) here.

Come on and join this fantastic project!


